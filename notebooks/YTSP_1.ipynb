{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HV4_NmfRuC0"
   },
   "source": [
    "**IMPORTED LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "g9VMXQkNITVZ",
    "outputId": "b5388581-d053-4d87-b66c-db2d7157a87e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4IvfhwLSBq1"
   },
   "source": [
    "**LOADING DATA FOR USE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BM_T09JASVi7"
   },
   "outputs": [],
   "source": [
    "train_file = '/content/drive/MyDrive/YTSP/Train.csv'  # Replace with your actual file path\n",
    "test_file = '/content/drive/MyDrive/YTSP/Test.csv'\n",
    "graph_file = '/content/drive/MyDrive/YTSP/Graph.csv'\n",
    "sample_submission_file = '/content/drive/MyDrive/YTSP/SampleSubmission.csv'\n",
    "\n",
    "# Load datasets\n",
    "train_data = pd.read_csv(train_file)\n",
    "test_data = pd.read_csv(test_file)\n",
    "graph_data = pd.read_csv(graph_file)\n",
    "sample_submission = pd.read_csv(sample_submission_file)\n",
    "\n",
    "# Check the shape and basic info of the train_data after loading\n",
    "print(f\"Shape of train_data: {train_data.shape}\")\n",
    "print(f\"Info about train_data:\\n{train_data.info()}\")\n",
    "\n",
    "# Check the first few rows to ensure it's not empty\n",
    "print(\"First few rows of train_data after loading:\")\n",
    "print(train_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRkH3RsZSci0"
   },
   "source": [
    "**EXAMINING AND CLEANING DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKIL3h3xSrUD"
   },
   "outputs": [],
   "source": [
    "# Check for missing values in the training and testing data\n",
    "print(\"Missing values in train_data:\")\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "# Fill or drop missing values (if necessary)\n",
    "train_data = train_data.dropna(subset=['target'])  # Drop rows where 'target' is missing\n",
    "\n",
    "# Ensure columns are clean (remove any extra spaces in column names)\n",
    "train_data.columns = train_data.columns.str.strip()\n",
    "\n",
    "# Convert categorical columns ('day' and 'prediction_type') to numeric values using Label Encoding or One-Hot Encoding\n",
    "# Convert 'day' column to categorical if it represents categories like days of the week\n",
    "train_data['day'] = pd.to_datetime(train_data['day'], errors='coerce').dt.dayofweek  # Convert to day of the week\n",
    "\n",
    "# Convert 'prediction_type' column to a numeric label (if it's categorical)\n",
    "train_data['prediction_type'] = train_data['prediction_type'].astype('category').cat.codes\n",
    "\n",
    "# Check the types of the columns\n",
    "print(\"Data types after conversion:\")\n",
    "print(train_data.dtypes)\n",
    "\n",
    "# Print columns of train_data\n",
    "print(f\"Columns in train_data after cleaning: {train_data.columns}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wycfGE6TZok"
   },
   "source": [
    "**TRAINING MODEL AND PREDICTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9aHVQx1qTx7s"
   },
   "outputs": [],
   "source": [
    "# Drop irrelevant columns for model training\n",
    "columns_to_drop = ['target', 'ID', 'timestamp', '15_min_interval']\n",
    "X_train = train_data.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Check the shape of X_train after dropping\n",
    "print(f\"Shape of X_train after dropping columns: {X_train.shape}\")\n",
    "print(f\"Columns in X_train after dropping: {X_train.columns}\")\n",
    "\n",
    "# Extract target\n",
    "y_train = train_data['target'] if 'target' in train_data.columns else None\n",
    "\n",
    "# Check for missing values in y_train\n",
    "print(f\"Missing values in y_train: {y_train.isnull().sum()}\")\n",
    "\n",
    "\n",
    "# Check if X_train and y_train are still valid\n",
    "if X_train.empty or y_train is None or y_train.empty:\n",
    "    print(\"Error: X_train or y_train is empty. Verify earlier steps.\")\n",
    "else:\n",
    "    print(\"Data appears ready for model training.\")\n",
    "\n",
    "\n",
    "# Model Training (Only proceed if data is valid)\n",
    "if not X_train.empty and y_train is not None and not y_train.empty:\n",
    "    # Example of training an XGBoost model\n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, max_depth=6)\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    X_test = test_data.drop(columns=['ID', 'timestamp', '15_min_interval'], errors='ignore')\n",
    "    \n",
    "    # Perform the same transformation on the test set as on X_train\n",
    "    X_test['day'] = pd.to_datetime(X_test['day'], errors='coerce').dt.dayofweek\n",
    "    X_test['prediction_type'] = X_test['prediction_type'].astype('category').cat.codes\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Save predictions to the sample submission file\n",
    "    sample_submission['target'] = predictions\n",
    "    sample_submission.to_csv('/content/drive/MyDrive/YTSP/Submissions.csv', index=False)\n",
    "\n",
    "    print(\"Model training and submission completed successfully.\")\n",
    "else:\n",
    "    print(\"Error: Model training skipped due to empty training data.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
